{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apurwa2024/Apurwa_INFO5731_FaLL2024/blob/main/Bhattarai_Apurwa_Exercise_4_Updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 4**\n",
        "\n",
        "**This exercise will provide a valuable learning experience in working with text data and extracting features using various topic modeling algorithms. Key concepts such as Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA), lda2vec, and BERTopic.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Please use the text corpus you collected in your last in-class-exercise for this exercise. Perform the following tasks***.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission, and no requests will be answered. Manage your time accordingly.**\n"
      ],
      "metadata": {
        "id": "TU-pLW33lpcS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "\n",
        "**Generate K topics by using LDA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "import nltk\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import CoherenceModel\n",
        "from pprint import pprint\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Check the file path\n",
        "file_path = '/content/gdrive/MyDrive/Colab Notebooks/data.csv'\n",
        "if os.path.exists(file_path):\n",
        "    print(\"File Found!\")\n",
        "\n",
        "    # Read data into papers\n",
        "    papers = pd.read_csv(file_path)\n",
        "\n",
        "    # Initial data shape\n",
        "    print(f\"Initial data shape: {papers.shape}\")\n",
        "    print(\"Columns in DataFrame:\", papers.columns)  # Print the column names\n",
        "\n",
        "    # Check if the expected column exists\n",
        "    if 'paper_text_processed' in papers.columns:\n",
        "        # Remove unnecessary columns and NaNs\n",
        "        papers = papers.drop(columns=['title', 'genres', 'releaseYear'], axis=1).sample(100)\n",
        "        papers.dropna(subset=['paper_text_processed'], inplace=True)\n",
        "\n",
        "        # Data shape after dropping NaNs\n",
        "        print(f\"Data shape after dropping NaNs: {papers.shape}\")\n",
        "\n",
        "        # Convert paper text to lowercase\n",
        "        papers['paper_text_processed'] = papers['paper_text_processed'].map(lambda x: x.lower())\n",
        "\n",
        "        # Download stopwords\n",
        "        nltk.download('stopwords')\n",
        "        stop_words = stopwords.words('english')\n",
        "        stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "\n",
        "        # Function to convert sentences to words\n",
        "        def sent_to_words(sentences):\n",
        "            for sentence in sentences:\n",
        "                yield gensim.utils.simple_preprocess(str(sentence), deacc=True)\n",
        "\n",
        "        # Function to remove stopwords\n",
        "        def remove_stopwords(texts):\n",
        "            return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "        # Prepare data for LDA\n",
        "        data = papers.paper_text_processed.values.tolist()\n",
        "        data_words = list(sent_to_words(data))\n",
        "\n",
        "        # Remove stop words\n",
        "        data_words = remove_stopwords(data_words)\n",
        "\n",
        "        # Create Dictionary and Corpus\n",
        "        id2word = corpora.Dictionary(data_words)\n",
        "        corpus = [id2word.doc2bow(text) for text in data_words]\n",
        "\n",
        "        # Coherence score calculation for various topics\n",
        "        coherence_scores = []\n",
        "        model_list = []\n",
        "        topic_range = range(2, 21)  # Testing K from 2 to 20\n",
        "\n",
        "        for num_topics in topic_range:\n",
        "            # Build LDA Model\n",
        "            lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=num_topics, random_state=42)\n",
        "            model_list.append(lda_model)\n",
        "\n",
        "            # Compute Coherence Score\n",
        "            coherence_model = CoherenceModel(model=lda_model, texts=data_words, dictionary=id2word, coherence='c_v')\n",
        "            coherence_score = coherence_model.get_coherence()\n",
        "            coherence_scores.append(coherence_score)\n",
        "            print(f'Coherence score with {num_topics} topics: {coherence_score}')\n",
        "\n",
        "        # Find the optimal number of topics\n",
        "        optimal_index = coherence_scores.index(max(coherence_scores))\n",
        "        optimal_topics = topic_range[optimal_index]\n",
        "        print(f'Optimal number of topics: {optimal_topics}')\n",
        "\n",
        "        # Build the final LDA model with the optimal number of topics\n",
        "        final_model = model_list[optimal_index]\n",
        "\n",
        "        # Print the topics and their distributions\n",
        "        print(\"\\nSummary of Topics:\")\n",
        "        for i, topic in enumerate(final_model.print_topics(num_words=10), start=1):\n",
        "            print(f\"Topic {i}:\")\n",
        "            print(\"  Key Words:\", topic[1].replace('\"', '').replace('+', '').strip())\n",
        "    else:\n",
        "        print(\"Column 'paper_text_processed' not found in DataFrame. Please check the CSV structure.\")\n",
        "else:\n",
        "    print(\"File not found. Please check the path.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEb4KAMN3zuT",
        "outputId": "91540cd6-2694-446f-8f0d-04e676f6e31c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "File Found!\n",
            "Initial data shape: (15860, 8)\n",
            "Columns in DataFrame: Index(['title', 'type', 'genres', 'releaseYear', 'imdbId', 'imdbAverageRating',\n",
            "       'imdbNumVotes', 'availableCountries'],\n",
            "      dtype='object')\n",
            "Column 'paper_text_processed' not found in DataFrame. Please check the CSV structure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "\n",
        "**Generate K topics by using LSA, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://www.datacamp.com/community/tutorials/discovering-hidden-topics-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from gensim.parsing.preprocessing import (\n",
        "    remove_stopwords, strip_punctuation, preprocess_string, strip_short, stem_text\n",
        ")\n",
        "from gensim import corpora\n",
        "from gensim.models import LsiModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/data.csv', usecols=['title', 'genres'])\n",
        "print(\"Initial data shape:\", df.shape)\n",
        "\n",
        "# Check for missing values in 'genres' column and drop rows with NaNs\n",
        "df = df.dropna()\n",
        "print(\"Data shape after dropping NaNs:\", df.shape)\n",
        "\n",
        "# Preprocess the text data\n",
        "def preprocess(text):\n",
        "    \"\"\"Apply custom filters to clean text.\"\"\"\n",
        "    CUSTOM_FILTERS = [\n",
        "        lambda x: x.lower(),\n",
        "        remove_stopwords,\n",
        "        strip_punctuation,\n",
        "        strip_short,\n",
        "        stem_text\n",
        "    ]\n",
        "    return preprocess_string(text, CUSTOM_FILTERS)\n",
        "\n",
        "# Apply the preprocess function to the 'genres' column\n",
        "df['Text (Clean)'] = df['genres'].apply(lambda x: preprocess(x))\n",
        "\n",
        "# Create dictionary and Bag-of-Words corpus\n",
        "corpus = df['Text (Clean)']\n",
        "dictionary = corpora.Dictionary(corpus)\n",
        "bow = [dictionary.doc2bow(text) for text in corpus]\n",
        "\n",
        "# Determine the coherence score for different numbers of topics\n",
        "coherence_scores = []\n",
        "for k in range(2, 11):\n",
        "    # Build LSA model for each number of topics\n",
        "    lsi = LsiModel(bow, num_topics=k, id2word=dictionary)\n",
        "    coherence_model = CoherenceModel(model=lsi, texts=corpus, dictionary=dictionary, coherence='c_v')\n",
        "    coherence_score = coherence_model.get_coherence()\n",
        "    coherence_scores.append((k, coherence_score))\n",
        "    print(f'Coherence score with {k} topics: {coherence_score}')\n",
        "\n",
        "# Find the optimal number of topics based on coherence score\n",
        "optimal_k = max(coherence_scores, key=lambda x: x[1])[0]\n",
        "print(f\"Optimal number of topics: {optimal_k}\")\n",
        "\n",
        "# Build final LSA model with the optimal number of topics\n",
        "lsa_model = LsiModel(bow, num_topics=optimal_k, id2word=dictionary)\n",
        "\n",
        "# Display the top words in each topic and interpret\n",
        "def summarize_topics(lsi_model):\n",
        "    topic_summaries = []\n",
        "\n",
        "    for topic_num, words in lsa_model.print_topics(num_words=10):\n",
        "        # Extract words from the topic\n",
        "        top_words = [word.split('*')[1].strip('\"') for word in words.split('+')]\n",
        "\n",
        "        # Interpretation and summary based on the top words\n",
        "        if topic_num == 0:\n",
        "            topic_summary = \"Mixed Genre Emphasis\"\n",
        "        elif topic_num == 1:\n",
        "            topic_summary = \"Comedy-Drama Dynamics\"\n",
        "        elif topic_num == 2:\n",
        "            topic_summary = \"Action and Adventure Focus\"\n",
        "        elif topic_num == 3:\n",
        "            topic_summary = \"Crime and Adventure Blend\"\n",
        "        elif topic_num == 4:\n",
        "            topic_summary = \"Romantic Drama and Family Themes\"\n",
        "        else:\n",
        "            topic_summary = \"General Topic\"\n",
        "\n",
        "        topic_summaries.append((f\"Topic {topic_num + 1}\", topic_summary, top_words))\n",
        "\n",
        "    return topic_summaries\n",
        "\n",
        "# Generate and print the topic summaries\n",
        "topic_summaries = summarize_topics(lsa_model)\n",
        "\n",
        "# Display the topic summaries\n",
        "print(\"\\nSummary of Topics:\")\n",
        "for topic_num, summary, words in topic_summaries:\n",
        "    print(f\"{topic_num}: {summary}\")\n",
        "    print(f\"  Key Words: {', '.join(words)}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRYYBeqRfTLx",
        "outputId": "129b2f6e-393c-4a3f-a077-e490486572ce",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Initial data shape: (15860, 2)\n",
            "Data shape after dropping NaNs: (15325, 2)\n",
            "Coherence score with 2 topics: 0.4048883816812441\n",
            "Coherence score with 3 topics: 0.4439403820366672\n",
            "Coherence score with 4 topics: 0.44045752914667363\n",
            "Coherence score with 5 topics: 0.45870395507963646\n",
            "Coherence score with 6 topics: 0.4843168841654058\n",
            "Coherence score with 7 topics: 0.46730430689084707\n",
            "Coherence score with 8 topics: 0.4482246007352817\n",
            "Coherence score with 9 topics: 0.49331837260868716\n",
            "Coherence score with 10 topics: 0.46864038682497844\n",
            "Optimal number of topics: 9\n",
            "\n",
            "Summary of Topics:\n",
            "Topic 1: Mixed Genre Emphasis\n",
            "  Key Words: drama\" , comedi\" , romanc\" , crime\" , action\" , adventur\" , thriller\" , anim\" , mysteri\" , fantasi\n",
            "\n",
            "Topic 2: Comedy-Drama Dynamics\n",
            "  Key Words: comedi\" , drama\" , adventur\" , anim\" , crime\" , thriller\" , mysteri\" , romanc\" , famili\" , biographi\n",
            "\n",
            "Topic 3: Action and Adventure Focus\n",
            "  Key Words: action\" , adventur\" , anim\" , romanc\" , crime\" , comedi\" , drama\" , thriller\" , sci\" , music\n",
            "\n",
            "Topic 4: Crime and Adventure Blend\n",
            "  Key Words: crime\" , adventur\" , anim\" , thriller\" , comedi\" , drama\" , romanc\" , mysteri\" , documentari\" , famili\n",
            "\n",
            "Topic 5: Romantic Drama and Family Themes\n",
            "  Key Words: romanc\" , action\" , drama\" , anim\" , comedi\" , famili\" , thriller\" , adventur\" , biographi\" , documentari\n",
            "\n",
            "Topic 6: General Topic\n",
            "  Key Words: thriller\" , horror\" , mysteri\" , documentari\" , crime\" , biographi\" , action\" , histori\" , fantasi\" , sci\n",
            "\n",
            "Topic 7: General Topic\n",
            "  Key Words: documentari\" , action\" , anim\" , romanc\" , mysteri\" , adventur\" , crime\" , drama\" , famili\" , horror\n",
            "\n",
            "Topic 8: General Topic\n",
            "  Key Words: documentari\" , crime\" , action\" , anim\" , thriller\" , biographi\" , histori\" , music\" , adventur\" , horror\n",
            "\n",
            "Topic 9: General Topic\n",
            "  Key Words: thriller\" , mysteri\" , horror\" , fantasi\" , anim\" , action\" , famili\" , sci\" , documentari\" , crime\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "**Generate K topics by using lda2vec, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://nbviewer.org/github/cemoody/lda2vec/blob/master/examples/twenty_newsgroups/lda2vec/lda2vec.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Note: I did an alternative question instead\n",
        "\n",
        "!pip install tensorflow==2.12 keras==2.12 lda2vec pandas nltk\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lda2vec import LDA2Vec\n",
        "import tensorflow as tf\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.corpora import Dictionary\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Load your data\n",
        "file_path = '/content/gdrive/MyDrive/Colab Notebooks/data.csv'\n",
        "papers = pd.read_csv(file_path)\n",
        "\n",
        "# Check the data shape and columns\n",
        "print(f\"Initial data shape: {papers.shape}\")\n",
        "print(\"Columns in DataFrame:\", papers.columns)\n",
        "\n",
        "# Assume we want to use the 'genres' column as the text data\n",
        "papers['text'] = papers['genres'].apply(lambda x: x.lower() if isinstance(x, str) else '')\n",
        "\n",
        "# Remove NaN values and any empty strings\n",
        "papers.dropna(subset=['text'], inplace=True)\n",
        "\n",
        "# Tokenize the text\n",
        "def tokenize(text):\n",
        "    return [word for word in text.split() if word not in stop_words]\n",
        "\n",
        "papers['tokenized'] = papers['text'].apply(tokenize)\n",
        "\n",
        "# Create a dictionary and corpus\n",
        "dictionary = Dictionary(papers['tokenized'])\n",
        "corpus = [dictionary.doc2bow(text) for text in papers['tokenized']]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test = train_test_split(corpus, test_size=0.2, random_state=42)\n",
        "\n",
        "# Coherence score calculation for various topics\n",
        "coherence_scores = []\n",
        "num_topics_range = range(2, 21)  # Testing K from 2 to 20\n",
        "\n",
        "for num_topics in num_topics_range:\n",
        "    lda2vec_model = LDA2Vec(corpus=X_train, n_topics=num_topics, dictionary=dictionary, n_epochs=100, learning_rate=0.01)\n",
        "    lda2vec_model.fit(X_train)\n",
        "\n",
        "    # Get the topics and their distributions\n",
        "    topic_word_distribution = lda2vec_model.get_topic_word_distribution()\n",
        "\n",
        "    # Prepare the documents for coherence calculation\n",
        "    topics_list = []\n",
        "    for topic_num in range(num_topics):\n",
        "        words = lda2vec_model.get_topic_words(topic_num, topn=10)\n",
        "        topics_list.append([word for word, _ in words])\n",
        "\n",
        "    # Calculate coherence score using Gensim\n",
        "    coherence_model = CoherenceModel(topics=topics_list, texts=papers['tokenized'].tolist(), dictionary=dictionary, coherence='c_v')\n",
        "    coherence_score = coherence_model.get_coherence()\n",
        "    coherence_scores.append((num_topics, coherence_score))\n",
        "    print(f'Coherence score with {num_topics} topics: {coherence_score:.4f}')\n",
        "\n",
        "# Find the optimal number of topics based on coherence score\n",
        "optimal_k = max(coherence_scores, key=lambda x: x[1])[0]\n",
        "print(f\"Optimal number of topics: {optimal_k}\")\n",
        "\n",
        "# Fit the final model with the optimal number of topics\n",
        "final_model = LDA2Vec(corpus=X_train, n_topics=optimal_k, dictionary=dictionary, n_epochs=100, learning_rate=0.01)\n",
        "final_model.fit(X_train)\n",
        "\n",
        "# Summarize topics\n",
        "print(\"\\nSummary of Topics:\")\n",
        "for topic_num in range(optimal_k):\n",
        "    words = final_model.get_topic_words(topic_num, topn=10)\n",
        "    print(f\"Topic {topic_num + 1}: {', '.join([word for word, _ in words])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wQ3_FaZo7Z-1",
        "outputId": "c8c25d22-1613-4fd6-eceb-8453dd5dbd44",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.12 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: keras==2.12 in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: lda2vec in /usr/local/lib/python3.10/dist-packages (0.16.10)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (24.3.25)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.64.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.12.1)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.4.30)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (18.1.1)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.12) (0.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.44.0)\n",
            "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.30)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.1)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.13.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'LDA2Vec' from 'lda2vec' (/usr/local/lib/python3.10/dist-packages/lda2vec/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cbe2d01d9100>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlda2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLDA2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'LDA2Vec' from 'lda2vec' (/usr/local/lib/python3.10/dist-packages/lda2vec/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "**Generate K topics by using BERTopic, the number of topics K should be decided by the coherence score, then summarize what are the topics.**\n",
        "\n",
        "You may refer the code here: https://colab.research.google.com/drive/1FieRA9fLdkQEGDIMYl0I3MCjSUKVF8C-?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09aa0561-03f6-473e-bc1f-63eb89bff4ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: typing_extensions 4.12.2\n",
            "Uninstalling typing_extensions-4.12.2:\n",
            "  Successfully uninstalled typing_extensions-4.12.2\n",
            "Found existing installation: bertopic 0.16.4\n",
            "Uninstalling bertopic-0.16.4:\n",
            "  Successfully uninstalled bertopic-0.16.4\n",
            "Found existing installation: sentence-transformers 3.2.1\n",
            "Uninstalling sentence-transformers-3.2.1:\n",
            "  Successfully uninstalled sentence-transformers-3.2.1\n",
            "Found existing installation: gensim 4.3.3\n",
            "Uninstalling gensim-4.3.3:\n",
            "  Successfully uninstalled gensim-4.3.3\n",
            "Collecting typing_extensions==4.5.0\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting bertopic\n",
            "  Using cached bertopic-0.16.4-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: umap-learn in /usr/local/lib/python3.10/dist-packages (0.5.7)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.8.39)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.23.5)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.2.2)\n",
            "Requirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.24.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.5.2)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.6)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.44.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.0+cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.60.0)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn) (0.5.13)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (9.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch>=1.11.0 (from sentence-transformers)\n",
            "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "  Downloading torch-2.5.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "  Downloading torch-2.4.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "  Downloading torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "  Downloading torch-2.2.2-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "INFO: pip is still looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "  Downloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.1.0 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Using cached bertopic-0.16.4-py3-none-any.whl (143 kB)\n",
            "Downloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m710.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: typing_extensions, triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, gensim, torch, sentence-transformers, bertopic\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.0+cu121\n",
            "    Uninstalling torch-2.5.0+cu121:\n",
            "      Successfully uninstalled torch-2.5.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.36 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "bigframes 1.25.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "chex 0.1.87 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "langchain-core 0.3.13 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "openai 1.52.2 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pyldavis 3.4.1 requires numpy>=1.24.2, but you have numpy 1.23.5 which is incompatible.\n",
            "pydantic 2.9.2 requires typing-extensions>=4.6.1; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pydantic-core 2.23.4 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.12.0 which is incompatible.\n",
            "torchaudio 2.5.0+cu121 requires torch==2.5.0, but you have torch 2.1.2 which is incompatible.\n",
            "torchvision 0.20.0+cu121 requires torch==2.5.0, but you have torch 2.1.2 which is incompatible.\n",
            "typeguard 4.4.0 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bertopic-0.16.4 gensim-4.3.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.2.1 torch-2.1.2 triton-2.1.0 typing_extensions-4.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gensim",
                  "torch",
                  "torchgen"
                ]
              },
              "id": "bf1716421aa543f899e65312e89108e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'Sequence' from 'typing_extensions' (/usr/local/lib/python3.10/dist-packages/typing_extensions.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-c5dd9d535d79>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCoherenceModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bertopic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBERTopic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bertopic\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/_bertopic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseCluster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseEmbedder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepresentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mmr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmmr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mselect_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/backend/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# OpenAI Embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mbertopic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAIBackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"`pip install openai` \\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/bertopic/backend/_openai.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mopenai\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_types\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNOT_GIVEN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotGiven\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProxiesTypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfile_from_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/types/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/types/batch.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch_error\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbatch_request_counts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchRequestCounts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTYPE_CHECKING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m from typing_extensions import (\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mUnpack\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mLiteral\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Sequence' from 'typing_extensions' (/usr/local/lib/python3.10/dist-packages/typing_extensions.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "!pip uninstall -y typing_extensions bertopic sentence-transformers gensim\n",
        "\n",
        "!pip install typing_extensions==4.5.0 bertopic sentence-transformers umap-learn gensim\n",
        "\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from bertopic import BERTopic\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/data.csv', usecols=['title', 'genres'])\n",
        "print(\"Initial data shape:\", df.shape)\n",
        "\n",
        "# Check for missing values in 'genres' column and drop rows with NaNs\n",
        "df = df.dropna()\n",
        "print(\"Data shape after dropping NaNs:\", df.shape)\n",
        "\n",
        "# Combine titles and genres for better context\n",
        "df['text'] = df['title'] + ' ' + df['genres']\n",
        "\n",
        "# Extract the text data\n",
        "documents = df['text'].tolist()\n",
        "\n",
        "# Create a dictionary for coherence calculation\n",
        "dictionary = Dictionary([doc.split() for doc in documents])\n",
        "\n",
        "# Initialize the BERTopic model\n",
        "coherence_scores = []\n",
        "num_topics_range = range(2, 11)  # Testing for 2 to 10 topics\n",
        "\n",
        "for num_topics in num_topics_range:\n",
        "    # Fit the model\n",
        "    model = BERTopic()  # No need to set n_topics here\n",
        "    topics, _ = model.fit_transform(documents)\n",
        "\n",
        "    # Get the topics and their words\n",
        "    topic_word_dist = model.get_topic_info()\n",
        "\n",
        "    # Prepare the documents for coherence calculation\n",
        "    topics_list = []\n",
        "    for topic in range(len(topic_word_dist) - 1):  # Exclude the outlier topic\n",
        "        words = model.get_topic(topic)\n",
        "        topics_list.append([word for word, _ in words if word in dictionary.token2id])  # Store only valid words\n",
        "\n",
        "    # Convert topics to a format suitable for CoherenceModel\n",
        "    topics_list_ids = []\n",
        "    for topic in topics_list:\n",
        "        topic_ids = [dictionary.token2id[word] for word in topic if word in dictionary.token2id]\n",
        "        if topic_ids:  # Ensure there's at least one valid ID\n",
        "            topics_list_ids.append(topic_ids)\n",
        "\n",
        "    # Calculate coherence score using Gensim\n",
        "    if topics_list_ids:  # Ensure there are topics to calculate coherence\n",
        "        coherence_model = CoherenceModel(topics=topics_list_ids, texts=[doc.split() for doc in documents], dictionary=dictionary, coherence='c_v')\n",
        "        coherence_score = coherence_model.get_coherence()\n",
        "        coherence_scores.append((num_topics, coherence_score))\n",
        "        print(f'Coherence score with {num_topics} topics: {coherence_score:.4f}')\n",
        "    else:\n",
        "        print(f'No valid topics found for {num_topics} topics.')\n",
        "\n",
        "# Find the optimal number of topics based on coherence score\n",
        "if coherence_scores:\n",
        "    optimal_k = max(coherence_scores, key=lambda x: x[1])[0]\n",
        "    print(f\"Optimal number of topics: {optimal_k}\")\n",
        "\n",
        "    # Fit the final model with the optimal number of topics\n",
        "    model = BERTopic()\n",
        "    topics, _ = model.fit_transform(documents)\n",
        "\n",
        "    # Summarize topics\n",
        "    topic_summaries = model.get_topic_info()\n",
        "\n",
        "    # Display the topic summaries\n",
        "    print(\"\\nSummary of Topics:\")\n",
        "    for index, row in topic_summaries.iterrows():\n",
        "        if row['Topic'] >= 0:  # Ignore the -1 topic which is the outlier\n",
        "            print(f\"Topic {row['Topic']}: {row['Name']}\")\n",
        "else:\n",
        "    print(\"No coherence scores calculated. Please check the topic generation step.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Question 3 (Alternative) - (10 points)**\n",
        "\n",
        "If you are unable to do the topic modeling using lda2vec, do the alternate question.\n",
        "\n",
        "Provide atleast 3 visualization for the topics generated by the BERTopic or LDA model. Explain each of the visualization in detail."
      ],
      "metadata": {
        "id": "Wslk2SYHML8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#LDA Model: Coherence Score Plot\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "import nltk\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Load data\n",
        "file_path = '/content/gdrive/MyDrive/Colab Notebooks/data.csv'\n",
        "papers = pd.read_csv(file_path)\n",
        "\n",
        "# Check the initial data shape and columns\n",
        "print(f\"Initial data shape: {papers.shape}\")\n",
        "print(\"Columns in DataFrame:\", papers.columns)\n",
        "\n",
        "# Specify the correct column name based on your CSV structure\n",
        "# Replace 'paper_text_processed' with the correct column name if needed\n",
        "text_column = 'paper_text_processed'  # Change this as needed\n",
        "\n",
        "# Data preprocessing\n",
        "if text_column in papers.columns:\n",
        "    papers = papers.drop(columns=['title', 'genres', 'releaseYear'], axis=1).sample(100)\n",
        "    papers.dropna(subset=[text_column], inplace=True)\n",
        "    papers[text_column] = papers[text_column].map(lambda x: x.lower())\n",
        "\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = stopwords.words('english')\n",
        "    stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "\n",
        "    def sent_to_words(sentences):\n",
        "        for sentence in sentences:\n",
        "            yield gensim.utils.simple_preprocess(str(sentence), deacc=True)\n",
        "\n",
        "    def remove_stopwords(texts):\n",
        "        return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "    data = papers[text_column].values.tolist()\n",
        "    data_words = list(sent_to_words(data))\n",
        "    data_words = remove_stopwords(data_words)\n",
        "\n",
        "    # Create Dictionary and Corpus\n",
        "    id2word = corpora.Dictionary(data_words)\n",
        "    corpus = [id2word.doc2bow(text) for text in data_words]\n",
        "\n",
        "    # Coherence score calculation\n",
        "    coherence_scores = []\n",
        "    topic_range = range(2, 21)\n",
        "    for num_topics in topic_range:\n",
        "        lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=num_topics, random_state=42)\n",
        "        coherence_model = CoherenceModel(model=lda_model, texts=data_words, dictionary=id2word, coherence='c_v')\n",
        "        coherence_score = coherence_model.get_coherence()\n",
        "        coherence_scores.append(coherence_score)\n",
        "        print(f'Coherence score with {num_topics} topics: {coherence_score:.4f}')\n",
        "\n",
        "    # Visualization: Coherence Score Plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(topic_range, coherence_scores, marker='o')\n",
        "    plt.title('Coherence Scores for Different Numbers of Topics')\n",
        "    plt.xlabel('Number of Topics')\n",
        "    plt.ylabel('Coherence Score')\n",
        "    plt.xticks(topic_range)\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"Column '{text_column}' not found in DataFrame. Available columns: {papers.columns.tolist()}\")\n",
        "\n",
        "\n",
        "    #Explanation: The coherence score plot visualizes how the coherence score changes with different numbers of topics, indicating how well the words in each topic relate to each other.\n",
        "    #             A peak in the plot shows the optimal number of topics, where the score is highest, suggesting the best representation of themes in the data.\n"
      ],
      "metadata": {
        "id": "eKZHcPjpNEDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "b5f9bd36-3151-458d-e658-75ae760fe6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Initial data shape: (15860, 8)\n",
            "Columns in DataFrame: Index(['title', 'type', 'genres', 'releaseYear', 'imdbId', 'imdbAverageRating',\n",
            "       'imdbNumVotes', 'availableCountries'],\n",
            "      dtype='object')\n",
            "Column 'paper_text_processed' not found in DataFrame. Available columns: ['title', 'type', 'genres', 'releaseYear', 'imdbId', 'imdbAverageRating', 'imdbNumVotes', 'availableCountries']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word Cloud\n",
        "\n",
        "\n",
        "!pip install wordcloud matplotlib\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "import nltk\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import CoherenceModel\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Check the file path\n",
        "file_path = '/content/gdrive/MyDrive/Colab Notebooks/data.csv'\n",
        "if os.path.exists(file_path):\n",
        "    print(\"File Found!\")\n",
        "\n",
        "    # Read data into papers\n",
        "    papers = pd.read_csv(file_path)\n",
        "\n",
        "    # Initial data shape\n",
        "    print(f\"Initial data shape: {papers.shape}\")\n",
        "\n",
        "    # Check if the expected column exists\n",
        "    if 'paper_text_processed' in papers.columns:\n",
        "        # Remove unnecessary columns and NaNs\n",
        "        papers = papers.drop(columns=['title', 'genres', 'releaseYear'], axis=1).sample(100)\n",
        "        papers.dropna(subset=['paper_text_processed'], inplace=True)\n",
        "\n",
        "        # Data shape after dropping NaNs\n",
        "        print(f\"Data shape after dropping NaNs: {papers.shape}\")\n",
        "\n",
        "        # Convert paper text to lowercase\n",
        "        papers['paper_text_processed'] = papers['paper_text_processed'].map(lambda x: x.lower())\n",
        "\n",
        "        # Download stopwords\n",
        "        nltk.download('stopwords')\n",
        "        stop_words = stopwords.words('english')\n",
        "        stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "\n",
        "        # Function to convert sentences to words\n",
        "        def sent_to_words(sentences):\n",
        "            for sentence in sentences:\n",
        "                yield gensim.utils.simple_preprocess(str(sentence), deacc=True)\n",
        "\n",
        "        # Function to remove stopwords\n",
        "        def remove_stopwords(texts):\n",
        "            return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "        # Prepare data for LDA\n",
        "        data = papers.paper_text_processed.values.tolist()\n",
        "        data_words = list(sent_to_words(data))\n",
        "\n",
        "        # Remove stop words\n",
        "        data_words = remove_stopwords(data_words)\n",
        "\n",
        "        # Create Dictionary and Corpus\n",
        "        id2word = corpora.Dictionary(data_words)\n",
        "        corpus = [id2word.doc2bow(text) for text in data_words]\n",
        "\n",
        "        # Coherence score calculation for various topics\n",
        "        coherence_scores = []\n",
        "        model_list = []\n",
        "        topic_range = range(2, 21)  # Testing K from 2 to 20\n",
        "\n",
        "        for num_topics in topic_range:\n",
        "            # Build LDA Model\n",
        "            lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=num_topics, random_state=42)\n",
        "            model_list.append(lda_model)\n",
        "\n",
        "            # Compute Coherence Score\n",
        "            coherence_model = CoherenceModel(model=lda_model, texts=data_words, dictionary=id2word, coherence='c_v')\n",
        "            coherence_score = coherence_model.get_coherence()\n",
        "            coherence_scores.append(coherence_score)\n",
        "            print(f'Coherence score with {num_topics} topics: {coherence_score}')\n",
        "\n",
        "        # Find the optimal number of topics\n",
        "        optimal_index = coherence_scores.index(max(coherence_scores))\n",
        "        optimal_topics = topic_range[optimal_index]\n",
        "        print(f'Optimal number of topics: {optimal_topics}')\n",
        "\n",
        "        # Build the final LDA model with the optimal number of topics\n",
        "        final_model = model_list[optimal_index]\n",
        "\n",
        "        # Word Cloud Visualization\n",
        "        topic_number = 0  # Change this to visualize different topics\n",
        "        words = final_model.show_topic(topic_number, topn=30)  # Get top 30 words for the topic\n",
        "        word_freq = {word: freq for word, freq in words}\n",
        "\n",
        "        # Create a word cloud\n",
        "        wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_freq)\n",
        "\n",
        "        # Display the word cloud\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.imshow(wordcloud, interpolation='bilinear')\n",
        "        plt.axis('off')\n",
        "        plt.title(f'Word Cloud for Topic {topic_number}')\n",
        "        plt.show()\n",
        "\n",
        "    else:\n",
        "        print(\"Column 'paper_text_processed' not found in DataFrame. Please check the CSV structure.\")\n",
        "else:\n",
        "    print(\"File not found. Please check the path.\")\n",
        "\n",
        "\n",
        "    #Explanation: The word cloud visualization displays the most significant words associated with a specific topic, where the size of each word indicates its importance or frequency within that topic. Larger words are more prominent\n",
        "    # providing an immense sense of the central themes associated with the topic. This visualization aids in quickly grasping the key ideas, making it easier to interpret and explore different topics generated by the LDA model.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCqFelGLY-W4",
        "outputId": "8097fbee-90fc-42cf-b604-cec631b0b5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.10/dist-packages (1.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from wordcloud) (1.26.4)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from wordcloud) (10.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "File Found!\n",
            "Initial data shape: (15860, 8)\n",
            "Column 'paper_text_processed' not found in DataFrame. Please check the CSV structure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Topic distribution Plot\n",
        "\n",
        "!pip install gensim nltk matplotlib\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "import nltk\n",
        "from gensim.utils import simple_preprocess\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import CoherenceModel\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Check the file path\n",
        "file_path = '/content/gdrive/MyDrive/Colab Notebooks/data.csv'\n",
        "if os.path.exists(file_path):\n",
        "    print(\"File Found!\")\n",
        "\n",
        "    # Read data into papers\n",
        "    papers = pd.read_csv(file_path)\n",
        "\n",
        "    # Initial data shape\n",
        "    print(f\"Initial data shape: {papers.shape}\")\n",
        "    print(\"Columns in DataFrame:\", papers.columns)\n",
        "\n",
        "    # Handle NaN values and convert text to lowercase\n",
        "    papers['paper_text_processed'] = papers['genres'].apply(lambda x: x.lower() if isinstance(x, str) else '')\n",
        "\n",
        "    # Remove unnecessary columns and NaNs\n",
        "    papers = papers.drop(columns=['title', 'type', 'releaseYear', 'imdbId', 'imdbAverageRating', 'imdbNumVotes', 'availableCountries'], axis=1).sample(100)\n",
        "    papers.dropna(subset=['paper_text_processed'], inplace=True)\n",
        "\n",
        "    # Download stopwords\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = stopwords.words('english')\n",
        "    stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
        "\n",
        "    # Function to convert sentences to words\n",
        "    def sent_to_words(sentences):\n",
        "        for sentence in sentences:\n",
        "            yield gensim.utils.simple_preprocess(str(sentence), deacc=True)\n",
        "\n",
        "    # Function to remove stopwords\n",
        "    def remove_stopwords(texts):\n",
        "        return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "    # Prepare data for LDA\n",
        "    data = papers.paper_text_processed.values.tolist()\n",
        "    data_words = list(sent_to_words(data))\n",
        "\n",
        "    # Remove stop words\n",
        "    data_words = remove_stopwords(data_words)\n",
        "\n",
        "    # Create Dictionary and Corpus\n",
        "    id2word = corpora.Dictionary(data_words)\n",
        "    corpus = [id2word.doc2bow(text) for text in data_words]\n",
        "\n",
        "    # Coherence score calculation for various topics\n",
        "    coherence_scores = []\n",
        "    model_list = []\n",
        "    topic_range = range(2, 21)  # Testing K from 2 to 20\n",
        "\n",
        "    for num_topics in topic_range:\n",
        "        # Build LDA Model\n",
        "        lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=num_topics, random_state=42)\n",
        "        model_list.append(lda_model)\n",
        "\n",
        "        # Compute Coherence Score\n",
        "        coherence_model = CoherenceModel(model=lda_model, texts=data_words, dictionary=id2word, coherence='c_v')\n",
        "        coherence_score = coherence_model.get_coherence()\n",
        "        coherence_scores.append(coherence_score)\n",
        "        print(f'Coherence score with {num_topics} topics: {coherence_score}')\n",
        "\n",
        "    # Find the optimal number of topics\n",
        "    optimal_index = coherence_scores.index(max(coherence_scores))\n",
        "    optimal_topics = topic_range[optimal_index]\n",
        "    print(f'Optimal number of topics: {optimal_topics}')\n",
        "\n",
        "    # Build the final LDA model with the optimal number of topics\n",
        "    final_model = model_list[optimal_index]\n",
        "\n",
        "    # Topic Distribution Plot\n",
        "    # Get the topic distribution for each document\n",
        "    topic_distribution = final_model.get_document_topics(corpus)\n",
        "\n",
        "    # Count the number of documents assigned to each topic\n",
        "    topic_counts = np.zeros(final_model.num_topics)\n",
        "    for doc in topic_distribution:\n",
        "        for topic_num, _ in doc:\n",
        "            topic_counts[topic_num] += 1\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(range(final_model.num_topics), topic_counts, color='skyblue')\n",
        "    plt.title('Topic Distribution Across Documents')\n",
        "    plt.xlabel('Topic Number')\n",
        "    plt.ylabel('Number of Documents')\n",
        "    plt.xticks(range(final_model.num_topics))\n",
        "    plt.grid(axis='y')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"File not found. Please check the path.\")\n",
        "\n",
        "    #Explanation: The topic distribution plot shows the number of docymentation associated with each topic generated by LDA Model. Each bar represents a topic, with the height of the bar inficating how many documnets were assigned\n",
        "    #to that topic, helping to visualize which topics are most prevalent in the dataset. This visualization is useful for understanding the relative importance and distribution of topics within the corpus, indicating which themes\n",
        "    #dominates the content.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sYtC5tvEa7fC",
        "outputId": "ec8c6225-2076-4afe-b0f1-c4c09d995573"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "File Found!\n",
            "Initial data shape: (15860, 8)\n",
            "Columns in DataFrame: Index(['title', 'type', 'genres', 'releaseYear', 'imdbId', 'imdbAverageRating',\n",
            "       'imdbNumVotes', 'availableCountries'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 2 topics: 0.640477559608347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 3 topics: 0.6457253386156488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 4 topics: 0.6601240104644199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 5 topics: 0.6622931351326237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 6 topics: 0.6579675359463638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 7 topics: 0.6632924882176974\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 8 topics: 0.6607007718603612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 9 topics: 0.6618096209081267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 10 topics: 0.6626769060448668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 11 topics: 0.6656940200446516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 12 topics: 0.6660227732031732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 13 topics: 0.6656807660153843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 14 topics: 0.6661307530525266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 15 topics: 0.6673265636144609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 16 topics: 0.6635400535099472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 17 topics: 0.6659116306344024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 18 topics: 0.6642199662689428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamulticore:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence score with 19 topics: 0.6640994882827019\n",
            "Coherence score with 20 topics: 0.660126715210974\n",
            "Optimal number of topics: 15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extra Question (5 Points)\n",
        "\n",
        "**Compare the results generated by the four topic modeling algorithms, which one is better? You should explain the reasons in details.**\n",
        "\n",
        "**This question will compensate for any points deducted in this exercise. Maximum marks for the exercise is 40 points.**"
      ],
      "metadata": {
        "id": "d89ODUx3jjJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "From all the modeling algorithm I found LDA model better because of the following reason:\n",
        "Interpretability: LDA provides easily interpretable topics by directly presenting the most relevant words associated with each topic.topic\n",
        "Simplicity: LDA is approach is straighforward allowing relatively easy implementation and tuning.\n",
        "Resource Efficient: Compared to other model that leverage deep learning, LDA is comparatively less demanding.\n"
      ],
      "metadata": {
        "id": "OK34nZtojhmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment.\n",
        "\n",
        "Consider the following points in your response:\n",
        "\n",
        "**Learning Experience:** Describe your overall learning experience in working with text data and extracting features using various topic modeling algorithms. Did you understand these algorithms and did the implementations helped in grasping the nuances of feature extraction from text data.\n",
        "\n",
        "**Challenges Encountered:** Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "My overall experience was good; however it was a bit challenging for me. Other than that I learned the fundamentals of how text data can be analyzed to identify underlying topics.\n",
        "I also learned about extracting features from text, such as identyfying keywords  and phrases that represents different topics.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}