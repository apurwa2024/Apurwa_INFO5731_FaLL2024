{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/apurwa2024/Apurwa_INFO5731_FaLL2024/blob/main/Bhattarai_Apurwa_Exercise_3_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 3**\n",
        "\n",
        "The purpose of this exercise is to explore various aspects of text analysis, including feature extraction, feature selection, and text similarity ranking.\n",
        "\n",
        "**Expectations**:\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of Friday, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n",
        "\n",
        "**Please check that the link you submitted can be opened and points to the correct assignment.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting **text classification or text mining task** and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features. **Your dataset must be text.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZj4PHB70nf"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "An interesting text classification could be offerup including different product categories. For example, description, title and price and later categories into furniture, bikes etc.\n",
        "\n",
        "1. Textual feature: this feature is used to extract from text data to help model learns patterns and understand relationship in texts. examples include: bag of words, N-grams, TF-IDF etc\n",
        "2. Price feature: It is a numerical represenation of the cost value which is useful to predict house price based on size, categorizing items into different range like low, medium and high.\n",
        "3. Seller feature: the rating of seller could affect the items that is being sold. If a seller has a high rating, chances are he is selling high value goods.\n",
        "4. Specific term: is the seller include a specific term its easier to categorize. For example, buyers type sofa or couch than it is most likely associated with furniture.\n",
        "5. Interaction feature: combining text feature with price could increase accuracy. For example, using word \"primitive\" with high price the category could most likely be furniture.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "from textblob import TextBlob\n",
        "import numpy as np\n",
        "import re\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Sample HTML content\n",
        "html_content = \"\"\"\n",
        "<html>\n",
        "  <body>\n",
        "    <div class=\"listing\">\n",
        "      <h2 class=\"title\">Second-Hand Couch</h2>\n",
        "      <p class=\"price\">$30</p>\n",
        "      <p class=\"description\">used couch but looks good.</p>\n",
        "    </div>\n",
        "    <div class=\"listing\">\n",
        "      <h2 class=\"title\">Skateboard</h2>\n",
        "      <p class=\"price\">$45</p>\n",
        "      <p class=\"description\">Skateboard for sale.</p>\n",
        "    </div>\n",
        "    <div class=\"listing\">\n",
        "      <h2 class=\"title\">Study Desk</h2>\n",
        "      <p class=\"price\">$125</p>\n",
        "      <p class=\"description\">A study desk, good for students.</p>\n",
        "    </div>\n",
        "  </body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "# Parse the HTML content with BeautifulSoup\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Extract product listings\n",
        "listings = soup.find_all('div', class_='listing')\n",
        "\n",
        "# Prepared a list to hold the data\n",
        "data = []\n",
        "for listing in listings:\n",
        "    title = listing.find('h2', class_='title').text\n",
        "    price = listing.find('p', class_='price').text\n",
        "    description = listing.find('p', class_='description').text\n",
        "    data.append({'title': title, 'description': description})\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Feature 1: Bag of Words\n",
        "count_vectorizer = CountVectorizer()\n",
        "bow_matrix = count_vectorizer.fit_transform(df['title'] + ' ' + df['description'])\n",
        "\n",
        "# Feature 2: TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['title'] + ' ' + df['description'])\n",
        "\n",
        "# Feature 3: Morphological Analysis\n",
        "def stem_words(text):\n",
        "    words = text.split()\n",
        "    return ' '.join([re.sub(r'(ing|ed|s)$', '', word) for word in words])\n",
        "\n",
        "df['stemmed'] = df['title'] + ' ' + df['description']\n",
        "df['stemmed'] = df['stemmed'].apply(stem_words)\n",
        "\n",
        "# Feature 4: Word Embedding\n",
        "sentences = [row.split() for row in df['stemmed']]\n",
        "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Create an average vector for each listing based on the words in the title and description\n",
        "def get_average_vector(text):\n",
        "    words = text.split()\n",
        "    vector = np.zeros(100)\n",
        "    count = 0\n",
        "    for word in words:\n",
        "        if word in word2vec_model.wv:\n",
        "            vector += word2vec_model.wv[word]\n",
        "            count += 1\n",
        "    return vector / count if count > 0 else vector\n",
        "\n",
        "df['embedding'] = df['stemmed'].apply(get_average_vector)\n",
        "\n",
        "# Feature 5: Semantic Analysis\n",
        "df['sentiment'] = df['description'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "# Combined features into a final DataFrame\n",
        "feature_df = pd.concat([\n",
        "    df[['title', 'description', 'sentiment']],\n",
        "    pd.DataFrame(bow_matrix.toarray(), columns=count_vectorizer.get_feature_names_out()),\n",
        "    pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out()),\n",
        "    pd.DataFrame(df['embedding'].tolist(), columns=[f'embed_{i}' for i in range(100)])\n",
        "], axis=1)\n",
        "\n",
        "# Display the feature DataFrame\n",
        "print(feature_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2dFkbx7HP-k",
        "outputId": "394238cb-8715-467b-b4c9-bd0da31f79d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               title                       description  sentiment  but  couch  \\\n",
            "0  Second-Hand Couch        used couch but looks good.        0.7    1      2   \n",
            "1         Skateboard              Skateboard for sale.        0.0    0      0   \n",
            "2         Study Desk  A study desk, good for students.        0.7    0      0   \n",
            "\n",
            "   desk  for  good  hand  looks  ...  embed_90  embed_91  embed_92  embed_93  \\\n",
            "0     0    0     1     1      1  ...  0.000949  0.001448  0.000337 -0.000137   \n",
            "1     0    1     0     0      0  ...  0.002830 -0.000366  0.001651 -0.002444   \n",
            "2     2    1     1     0      0  ...  0.000874  0.002089  0.001089 -0.000180   \n",
            "\n",
            "   embed_94  embed_95  embed_96  embed_97  embed_98  embed_99  \n",
            "0  0.003118  0.001339  0.001929 -0.003381  0.000586 -0.001534  \n",
            "1 -0.000364  0.002606  0.002808 -0.004326 -0.003576  0.001823  \n",
            "2  0.003795 -0.000367  0.000048  0.002937  0.001586  0.004486  \n",
            "\n",
            "[3 rows x 129 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Step 1: Load the Data\n",
        "df = pd.DataFrame({\n",
        "    'description': ['Sofa in good condition', 'Mountain bike for sale', 'Dining table set'],\n",
        "    'title': ['Sofa', 'Bike', 'Table'],\n",
        "    'price': [200, 150, 300],\n",
        "\n",
        "})\n",
        "\n",
        "# Step 2: Preprocess the Text\n",
        "df['text'] = df['title'] + ' ' + df['description']\n",
        "\n",
        "# Step 3: Vectorize the Text Data\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = tfidf_vectorizer.fit_transform(df['text'])\n",
        "\n",
        "# Step 5: Applying the Chi-Squared Test\n",
        "chi2_scores, p_values = chi2(X, y)\n",
        "\n",
        "# Step 6: Creating a DataFrame for Features and Scores\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "chi2_results = pd.DataFrame({'feature': feature_names, 'chi2_score': chi2_scores})\n",
        "\n",
        "# Ranking the features based on Chi-Squared scores in descending order\n",
        "chi2_results = chi2_results.sort_values(by='chi2_score', ascending=False)\n",
        "\n",
        "# Display the ranked features\n",
        "print(chi2_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FXPYCVesgr1",
        "outputId": "5be1a731-5585-46f4-d6e6-609d7397a63c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     feature  chi2_score\n",
            "0       bike    1.632993\n",
            "4   mountain    0.816497\n",
            "5       sale    0.816497\n",
            "7       sofa    0.408248\n",
            "8      table    0.408248\n",
            "1  condition    0.204124\n",
            "2     dining    0.204124\n",
            "3       good    0.204124\n",
            "6        set    0.204124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "817ff302-6381-46e0-df65-c673a0ddb77f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked documents based on similarity to the query:\n",
            "Document: Second-Hand Couch used couch but looks good | Similarity: 0.8916\n",
            "Document: Study Desk A study desk, good for students | Similarity: 0.7630\n",
            "Document: Skateboard Skateboard for sale | Similarity: 0.6850\n"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Loaded the pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Sample text data\n",
        "documents = [\n",
        "    \"Second-Hand Couch used couch but looks good\",\n",
        "    \"Skateboard Skateboard for sale\",\n",
        "    \"Study Desk A study desk, good for students\"\n",
        "]\n",
        "\n",
        "# example query\n",
        "query = \"Second-Hand Couch looks good\"\n",
        "\n",
        "# Function to get BERT embeddings\n",
        "def get_bert_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
        "    return cls_embedding.squeeze().numpy()\n",
        "\n",
        "# BERT embeddings for documents and the query\n",
        "document_embeddings = np.array([get_bert_embedding(doc) for doc in documents])\n",
        "query_embedding = get_bert_embedding(query)\n",
        "\n",
        "# cosine similarity between query and documents\n",
        "cosine_similarities = cosine_similarity([query_embedding], document_embeddings).flatten()\n",
        "\n",
        "# Ranked documents in descending order based on similarity\n",
        "ranked_indices = np.argsort(cosine_similarities)[::-1]\n",
        "\n",
        "# Output ranked documents\n",
        "print(\"Ranked documents based on similarity to the query:\")\n",
        "for idx in ranked_indices:\n",
        "    print(f\"Document: {documents[idx]} | Similarity: {cosine_similarities[idx]:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on extracting features from text data. What were the key concepts or techniques you found most beneficial in understanding the process?\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "\n",
        "This assignment was challenging for me but there were a lot of learning opportunities. Tokenization, TF-IDF and bag of words were something that I found beneficial.\n",
        "\n",
        "The challenges I encounter was data preprocessing where cleaning data was challenging.\n",
        "\n",
        "This exercise is useful for text classification, feature extraction and information retrieval.\n",
        "\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}